import torch
import numpy as np
from numpy.core._multiarray_umath import ndarray

from sklearn.decomposition import PCA


class pca():
    def __init__(self, args, components):
        super().__init__()

        self.model = PCA(n_components=components)

    def train(self, data_loaders):
        data_list = []
        for data, label in data_loaders['train']:
            data = torch.flatten(data, 1)
            data_list.append(data)

        images = torch.cat(data_list, dim=0)

        self.model.fit(images)

        v_ratio = self.model.explained_variance_ratio_
        print(np.sum(v_ratio))

    def extract_features(self, data_loaders, dl_type):
        data_list = []
        label_list = []
        for data, label in data_loaders[dl_type]:
            data = torch.flatten(data, 1)
            data = data.cpu()
            data_list.append(data)

            if dl_type == 'unknown':
                label = label.cpu()
                label_list.append(label)

        images = torch.cat(data_list, dim=0)
        features = self.model.transform(images)

        if dl_type == 'unknown':
            labels = np.array(torch.cat(label_list, dim=0))
            labels = np.where((labels == 3) | (labels == 4), 1, -1)
        else:
            labels = np.ones(len(features), int)

        return features, labels
