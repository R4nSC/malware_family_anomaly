import os
import random
import numpy as np
from torch.utils import data
from torchvision import datasets, transforms

from config import *


class BinaryBalancedSampler:
    def __init__(self, features, labels, n_samples):
        self.features = features
        self.labels = labels

        label_counts = np.bincount(labels)
        major_label = label_counts.argmax()
        minor_label = label_counts.argmin()

        self.major_indices = np.where(labels == major_label)[0]
        self.minor_indices = np.where(labels == minor_label)[0]

        np.random.shuffle(self.major_indices)
        np.random.shuffle(self.minor_indices)

        self.used_indices = 0
        self.count = 0
        self.n_samples = n_samples
        self.batch_size = self.n_samples * 2

    def __iter__(self):
        self.count = 0
        while self.count + self.batch_size < len(self.major_indices):
            # 多数派データ(major_indices)からは順番に選び出し
            # 少数派データ(minor_indices)からはランダムに選び出す操作を繰り返す
            indices = self.major_indices[self.used_indices:self.used_indices + self.n_samples].tolist() + \
                      np.random.choice(self.minor_indices, self.n_samples, replace=False).tolist()
            yield torch.tensor(self.features[indices]), torch.tensor(self.labels[indices])

            self.used_indices += self.n_samples
            self.count += self.n_samples * 2


# データの前処理
def data_preprocessing(args):
    # データの前処理を設定
    data_transforms = {
        'known': transforms.Compose([
            transforms.Resize([224, 224]),
            transforms.Grayscale(num_output_channels=3),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'unknown': transforms.Compose([
            transforms.Resize([224, 224]),
            transforms.Grayscale(num_output_channels=3),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
    }

    image_datasets = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x])
                      for x in ['known', 'unknown']}

    '''
    random_image_datasets = random.sample(image_datasets['known'], len(image_datasets['known']))
    for image in random_image_datasets:
        input, label = image
        print(label)
    '''

    # 訓練(train)，検証(val)，評価(test)のデータ分割サイズを定義
    train_ratio = 0.6
    val_ratio = 0.2
    train_size = int(train_ratio * len(image_datasets['known']))
    val_size = int(val_ratio * len(image_datasets['known']))
    test_size = len(image_datasets['known']) - train_size - val_size
    datasets_size = {"train": train_size, "val": val_size, "test": test_size,
                     "unknown": len(image_datasets['unknown'])}

    # 既知のマルウェアファミリのデータセットを3種類に分割
    train_datasets, val_datasets, test_datasets = torch.utils.data.random_split(image_datasets['known'],
                                                                                    [train_size, val_size, test_size])

    # 各ファミリのサンプル数を出力する
    train_class_number = [0] * 20
    features = []
    labels = []
    for image in train_datasets:
        # 入力データ(バッチサイズ分)
        input, label = image
        features.append(input)
        labels.append(label)
        train_class_number[label] += 1

    print(train_class_number)

    balanced_loader = BinaryBalancedSampler(features=features, labels=labels, n_samples=args.batch_size)

    # データローダを作成
    train_loader = torch.utils.data.DataLoader(train_datasets, batch_size=args.batch_size, shuffle=True)
    val_loader = torch.utils.data.DataLoader(val_datasets, batch_size=args.batch_size, shuffle=True)
    test_loader = torch.utils.data.DataLoader(test_datasets, batch_size=args.batch_size, shuffle=True)
    unknown_loader = torch.utils.data.DataLoader(image_datasets['unknown'], batch_size=args.batch_size, shuffle=True)
    data_loaders = {"train": train_loader, "val": val_loader, "test": test_loader,
                    "unknown": unknown_loader}

    # 既知クラスと未知クラスのファミリ名を保存
    class_names = {"known": image_datasets['known'].classes, "unknown": image_datasets['unknown'].classes}

    return data_loaders, datasets_size, class_names, train_class_number
