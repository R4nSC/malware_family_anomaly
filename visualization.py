import torch
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.metrics import confusion_matrix
import torchvision


# 画像の表示
def image_show(img):
    img = img / 2 + 0.5
    np_img = img.numpy()
    plt.imshow(np.transpose(np_img, (1, 2, 0)))
    plt.show()


# マルウェアの画像化(前処理等)のデバッグ
def malware_image_debug(data_loaders, class_names):
    # 訓練データをランダムに取得
    data_iter = iter(data_loaders["train"])
    images, labels = data_iter.next()

    # 画像の表示
    image_show(torchvision.utils.make_grid(images))
    # ラベルの表示
    print(' '.join('%5s' % class_names['known'][labels[j]] for j in range(8)))


# 学習の可視化
def train_visualization(loss, acc, epoch):
    # 学習の可視化
    loss_train = loss["train"]
    loss_val = loss["val"]

    acc_train = acc["train"]
    acc_val = acc["val"]

    # このように書く事で、nrows x cols のグラフを作成する事ができます。
    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))

    # ０個目のグラフ
    axes[0].plot(range(epoch), loss_train, label="train")
    axes[0].plot(range(epoch), loss_val, label="val")
    axes[0].set_title("Loss")
    axes[0].legend()  # 各グラフのlabelを表示

    # １個目のグラフ
    axes[1].plot(range(epoch), acc_train, label="train")
    axes[1].plot(range(epoch), acc_val, label="val")
    axes[1].set_title("Accuracy")
    axes[1].legend()

    # ０個目と１個目のグラフが重ならないように調整
    fig.tight_layout()

    # 出力
    plt.show()


# 多クラス分類の結果(混同行列)を可視化
def multi_classification_result_visualization(true_labels, pred_labels):
    # 混同行列に付与するラベルの取得
    labels = true_labels.to('cpu').detach().numpy().copy()
    labels = sorted(list(set(labels)))

    # 混同行列の計算
    df = pd.DataFrame(confusion_matrix(true_labels.cpu(), pred_labels.cpu()), index=labels, columns=labels)

    # GUIへの出力
    plt.figure()
    sns.heatmap(df, annot=True)  # annot = Falseにすると図中の各セルの数値表示がなくなる。
    # plt.ticklabel_format(useOffset=False)
    plt.show()


# 2値分類の結果を可視化
def Binary_classification_result_visualization():
    return 1


# t-SNEを用いて2次元に圧縮したEmbeddingを可視化する
def embedding_tsne_visualization(known_features, unknown_features):
    known_labels = torch.ones(known_features.size(0))
    unknown_labels = torch.zeros(unknown_features.size(0))

    labels = torch.cat((known_labels, unknown_labels), 0)
    features = torch.cat((known_features, unknown_features), 0)

    tsne = TSNE(n_components=2)  # n_componentsは低次元データの次元数
    tsne_result = tsne.fit_transform(features)

    colors = ['red', 'blue']
    plt.xlim(tsne_result[:, 0].min(), tsne_result[:, 0].max() + 1)
    plt.ylim(tsne_result[:, 1].min(), tsne_result[:, 1].max() + 1)
    for i in range(len(features)):
        plt.text(
            tsne_result[i, 0],
            tsne_result[i, 1],
            str(int(labels[i].item())),
            color=colors[int(labels[i].item())]
        )
    plt.xlabel('t-SNE Feature1')
    plt.ylabel('t-SNE Feature2')

    plt.show()
